{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import Stream\n",
    "from tweepy import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "import json\n",
    "import numpy as np\n",
    "import jsonpickle\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will query the Twitter API with given parameters and write the results to a file. We're using the `tweepy` Python library for the API access.\n",
    "\n",
    "The scripts expects there to be a file `.secrets` in the same directory in which the Twitter API keys are stored. The file format is a plain text file with each key in their own line without any additions, in order of consumer key, consumer secret, access token, access secret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pyykkomi/.local/lib/python3.5/site-packages/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown.\n",
      "  warnings.warn(warning, RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(\".secrets\", \"r\") as f:\n",
    "        api_keys = f.readlines()\n",
    "    except:\n",
    "        print(\"no secrets file or error\")\n",
    "        exit()\n",
    "    \n",
    "consumer_key = api_keys[0]\n",
    "consumer_secret = api_keys[1]\n",
    "\n",
    "access_token = api_keys[2]\n",
    "access_secret = api_keys[3]\n",
    "\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will create the query from the words and tags we want to look for. Parameter `FILENAME` is expected to contain the name of the `.json` file we want to read and write to.\n",
    "\n",
    "Tweets have a rolling id which increases in time. In case the script has to be restarted, the existing file is read and the smallest existing id is given as maximum id to the query, so as not to get duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [\n",
    "    \"fortnite\", \"#fortnite\",\n",
    "    \"overwatch\", \"#overwatch\",\n",
    "    \"blackops4\", \"#blackops4\",\n",
    "    \"#blackout\",\n",
    "    \"#bo4\",\n",
    "    \"black ops 4\"\n",
    "]\n",
    "\n",
    "query_term = \" OR \".join(query)\n",
    "\n",
    "FILENAME = \"<TWEET_FILENAME>\"\n",
    "\n",
    "max_id = float('inf')\n",
    "\n",
    "try:\n",
    "    tweetfile = open(FILENAME, \"r\").read()\n",
    "    tweets = [json.loads(str(line)) for line in tweetfile.strip().split('\\n')]\n",
    "    max_id = min([tweet['id'] for tweet in tweets])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"max {}\".format(max_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweet query includes the query term, language wanted - Twitter tries to guess the language itself - and the maximum id of tweets. The tweets are queried in an endless loop and appended to file in `JSON` format. In case of error - which, in this case, is mostly the tweet limit reached - we will wait for 15 minutes before trying again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILENAME, \"a\") as f:\n",
    "    cursor = tweepy.Cursor(api.search, q=query_term, lang=\"en\", max_id=max_id, tweet_mode=\"extended\").items(1000000)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            tweet = cursor.next()\n",
    "            f.write(jsonpickle.encode(tweet._json, unpicklable=False) + \"\\n\")\n",
    "        except tweepy.TweepError as e:\n",
    "            print(\"err: \" + str(e))\n",
    "            time.sleep(60 * 15)\n",
    "            continue\n",
    "        except KeyboardInterrupt:\n",
    "            exit(1)\n",
    "        except:\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
